{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_URL=[]\n",
    "Product_Name=[]\n",
    "Product_Price=[]\n",
    "rating=[]\n",
    "Reviews=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1688716114&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
    "driver= webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "time.sleep(3)\n",
    "previous_height = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(3)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight') \n",
    "    if new_height == previous_height:\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    a=[\"a-size-medium a-color-base a-text-normal\",\"a-size-base-plus a-color-base a-text-normal\"]\n",
    "    n1=soup.find_all(\"span\",class_=a)\n",
    "    for i in n1:\n",
    "        n1=i.text\n",
    "        Product_Name.append(n1)\n",
    "            \n",
    "            #print(name)\n",
    "            #len(Product_Name)\n",
    "    n2=soup.find_all(\"span\",class_=\"a-price-whole\")\n",
    "    for i in n2:\n",
    "        n2=i.text\n",
    "        Product_Price.append(n2)\n",
    "            #print(name)\n",
    "            #len(Product_Price)\n",
    "    n3=soup.find_all(\"span\",class_=\"a-icon-alt\")\n",
    "    for i in n3:\n",
    "        n3=i.text\n",
    "        rating.append(n3)\n",
    "            #print(name)\n",
    "            #len(rating)\n",
    "    n4=soup.find_all(\"span\",class_=\"a-size-base s-underline-text\")\n",
    "    for i in n4:\n",
    "        n4=i.text\n",
    "        Reviews.append(n4)\n",
    "            #print(name)\n",
    "            #len(Reviews)\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "    for link in links:\n",
    "        Product_URL.append(link.get('href'))\n",
    "            #len(Product_URL)\n",
    "\n",
    "for i in range(2,21):\n",
    "    URL=f'https://www.amazon.in/s?k=bags&page={i}&crid=2M096C61O4MLT&qid=1688714478&sprefix=ba%2Caps%2C283&ref=sr_pg_{i}'\n",
    "    driver= webdriver.Chrome()\n",
    "    driver.get(URL)\n",
    "    time.sleep(3)\n",
    "    previous_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(3)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight') \n",
    "        if new_height == previous_height:\n",
    "            break\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        a=[\"a-size-medium a-color-base a-text-normal\",\"a-size-base-plus a-color-base a-text-normal\"]\n",
    "        n1=soup.find_all(\"span\",class_=a)\n",
    "        for i in n1:\n",
    "            n1=i.text\n",
    "            Product_Name.append(n1)\n",
    "            \n",
    "            #print(name)\n",
    "            #len(Product_Name)\n",
    "        n2=soup.find_all(\"span\",class_=\"a-price-whole\")\n",
    "        for i in n2:\n",
    "            n2=i.text\n",
    "            Product_Price.append(n2)\n",
    "            #print(name)\n",
    "            #len(Product_Price)\n",
    "        n3=soup.find_all(\"span\",class_=\"a-icon-alt\")\n",
    "        for i in n3:\n",
    "            n3=i.text\n",
    "            rating.append(n3)\n",
    "            #print(name)\n",
    "            #len(rating)\n",
    "        n4=soup.find_all(\"span\",class_=\"a-size-base s-underline-text\")\n",
    "        for i in n4:\n",
    "            n4=i.text\n",
    "            Reviews.append(n4)\n",
    "            #print(name)\n",
    "            #len(Reviews)\n",
    "        links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "        for link in links:\n",
    "            Product_URL.append(link.get('href'))\n",
    "            #len(Product_URL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99902501",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Product_Name\":Product_Name, \"Product_Price\":Product_Price, \"rating\":rating, \"Reviews\":Reviews,\"Product_URL\":Product_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea88f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description=[]\n",
    "ASIN=[]\n",
    "Product_Description=[]\n",
    "Manufacturer=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edcbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser \n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import time\n",
    "\n",
    "Description=[]\n",
    "\n",
    "ASIN=[]\n",
    "\n",
    "Product_Description=[]\n",
    "\n",
    "Manufacturer=[]\n",
    "a=[\"https://www.amazon.in/\" + Product_URL for Product_URL in Product_URL]\n",
    "for i in a:\n",
    "\n",
    "    driver= webdriver.Chrome()\n",
    "\n",
    "    driver.get(i)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    previous_h = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    " \n",
    "\n",
    "    while True:\n",
    "\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    " \n",
    "\n",
    "        new_h = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "        if new_h == previous_h:\n",
    "\n",
    "            break\n",
    "\n",
    "       \n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    #print(soup)\n",
    "\n",
    "    n5=soup.find_all(\"div\",id='feature-bullets')\n",
    "\n",
    "    for i in n5:\n",
    "\n",
    "        n5=i.text\n",
    "\n",
    "        Description.append(n5)\n",
    "\n",
    "\n",
    "    asin_li = soup.select_one('li:has(span.a-text-bold:contains(\"ASIN\"))')\n",
    "\n",
    "    if asin_li:\n",
    "    # Get the ASIN number by accessing the span element within the li\n",
    "        asin_number = asin_li.select_one('span:not(.a-text-bold)').text.strip()\n",
    "        asin_number = asin_number.replace('\\n', '').replace('\\u200f', '').replace('\\u200e', '')\n",
    "        ASIN.append(asin_number.strip())\n",
    "\n",
    "\n",
    "    d1=soup.find_all('div', id='productDescription')\n",
    "\n",
    "    for i in d1:\n",
    "\n",
    "        d2=i.text\n",
    "\n",
    "        Product_Description.append(d2)\n",
    "\n",
    "    manufacturer_li = soup.select_one('li:has(span.a-text-bold:contains(\"Manufacturer\"))')\n",
    "\n",
    "    if manufacturer_li:\n",
    "\n",
    "        manufacturer = manufacturer_li.select_one('span:not(.a-text-bold)').text.strip()\n",
    "        manufacturer = manufacturer.replace('\\n', '').replace('\\u200f', '').replace('\\u200e', '')\n",
    "   \n",
    "        Manufacturer.append(manufacturer.strip())\n",
    "    #print(manufacturer.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2={\"Description\":Description,\"ASIN\":ASIN,\"Product Description\":Product_Description,\"Manufacturer\":Manufacturer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(d, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fde67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_= pd.DataFrame.from_dict(d2, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572452ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"Python_assignment_part_-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40feffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Python_assignment_part_-2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
